{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "\n",
    "# \"Sequential\" models let usv define a stack of neural network layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "# import the core layers:\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "import numpy as np\n",
    "# import some utilities to transform/preprocess our data:\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = test_df.columns.values\n",
    "test = test_df[feature_cols]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = train_df.columns.values\n",
    "\n",
    "# use the above list to select the features from the original DataFrame\n",
    "X = train_df[feature_cols]  \n",
    "X = X.drop(['label'], axis=1)\n",
    "\n",
    "# select target vector from the DataFrame\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply scale the features to the range of [0,1]:\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding for the output label:\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31500, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Label after OneHotEncoding:\n",
    "print (y_train.shape)\n",
    "print (y_train[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Sequential model to build our network:\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_neurons = 100\n",
    "out_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Designing the NN Structure:\n",
    "\n",
    "# -----------------------------------------\n",
    "# first layer: input layer\n",
    "# Input layer does not do any processing, so no need to define the input layer in this problem.\n",
    "\n",
    "# -----------------------------------------\n",
    "# second layer: hidden layer:\n",
    "model.add(Dense(hidden_neurons, input_dim = input_size))  # Nuerons\n",
    "model.add(Activation('sigmoid')) # Activation\n",
    "\n",
    "# -----------------------------------------\n",
    "# third layer: output layer:\n",
    "model.add(Dense(out_size, input_dim = hidden_neurons))  # Nuerons\n",
    "model.add(Activation('softmax')) # Activation\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "\n",
    "# more info about loss functions: https://keras.io/losses\n",
    "# more infor about Optimizers: https://keras.io/optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21104 samples, validate on 10396 samples\n",
      "Epoch 1/100\n",
      "21104/21104 [==============================] - 1s 61us/step - loss: 0.7462 - acc: 0.8325 - val_loss: 0.3987 - val_acc: 0.8984\n",
      "Epoch 2/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.3315 - acc: 0.9106 - val_loss: 0.2958 - val_acc: 0.9162\n",
      "Epoch 3/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.2634 - acc: 0.9258 - val_loss: 0.2569 - val_acc: 0.9261\n",
      "Epoch 4/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.2239 - acc: 0.9373 - val_loss: 0.2364 - val_acc: 0.9299\n",
      "Epoch 5/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.1955 - acc: 0.9453 - val_loss: 0.2115 - val_acc: 0.9400\n",
      "Epoch 6/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.1734 - acc: 0.9524 - val_loss: 0.1953 - val_acc: 0.9432\n",
      "Epoch 7/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.1545 - acc: 0.9569 - val_loss: 0.1873 - val_acc: 0.9449\n",
      "Epoch 8/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.1389 - acc: 0.9611 - val_loss: 0.1757 - val_acc: 0.9483\n",
      "Epoch 9/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.1249 - acc: 0.9648 - val_loss: 0.1723 - val_acc: 0.9481\n",
      "Epoch 10/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.1137 - acc: 0.9686 - val_loss: 0.1620 - val_acc: 0.9533\n",
      "Epoch 11/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.1030 - acc: 0.9720 - val_loss: 0.1577 - val_acc: 0.9529\n",
      "Epoch 12/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0936 - acc: 0.9754 - val_loss: 0.1518 - val_acc: 0.9554\n",
      "Epoch 13/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0856 - acc: 0.9775 - val_loss: 0.1474 - val_acc: 0.9582\n",
      "Epoch 14/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0773 - acc: 0.9801 - val_loss: 0.1430 - val_acc: 0.9574\n",
      "Epoch 15/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0714 - acc: 0.9820 - val_loss: 0.1429 - val_acc: 0.9586\n",
      "Epoch 16/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0642 - acc: 0.9843 - val_loss: 0.1392 - val_acc: 0.9586\n",
      "Epoch 17/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0581 - acc: 0.9859 - val_loss: 0.1372 - val_acc: 0.9603\n",
      "Epoch 18/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0531 - acc: 0.9884 - val_loss: 0.1374 - val_acc: 0.9603\n",
      "Epoch 19/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0484 - acc: 0.9887 - val_loss: 0.1344 - val_acc: 0.9619\n",
      "Epoch 20/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0441 - acc: 0.9905 - val_loss: 0.1307 - val_acc: 0.9616\n",
      "Epoch 21/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0398 - acc: 0.9918 - val_loss: 0.1317 - val_acc: 0.9626\n",
      "Epoch 22/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0360 - acc: 0.9925 - val_loss: 0.1322 - val_acc: 0.9610\n",
      "Epoch 23/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0323 - acc: 0.9940 - val_loss: 0.1301 - val_acc: 0.9631\n",
      "Epoch 24/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0290 - acc: 0.9954 - val_loss: 0.1316 - val_acc: 0.9622\n",
      "Epoch 25/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0261 - acc: 0.9958 - val_loss: 0.1309 - val_acc: 0.9626\n",
      "Epoch 26/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0233 - acc: 0.9970 - val_loss: 0.1309 - val_acc: 0.9639\n",
      "Epoch 27/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0211 - acc: 0.9975 - val_loss: 0.1306 - val_acc: 0.9627\n",
      "Epoch 28/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0186 - acc: 0.9983 - val_loss: 0.1308 - val_acc: 0.9635\n",
      "Epoch 29/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0167 - acc: 0.9982 - val_loss: 0.1319 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 30/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0138 - acc: 0.9989 - val_loss: 0.1299 - val_acc: 0.9638\n",
      "Epoch 31/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0128 - acc: 0.9991 - val_loss: 0.1301 - val_acc: 0.9638\n",
      "Epoch 32/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0122 - acc: 0.9989 - val_loss: 0.1305 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 33/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0109 - acc: 0.9994 - val_loss: 0.1305 - val_acc: 0.9638\n",
      "Epoch 34/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0104 - acc: 0.9994 - val_loss: 0.1312 - val_acc: 0.9636\n",
      "Epoch 35/100\n",
      "21104/21104 [==============================] - 1s 51us/step - loss: 0.0101 - acc: 0.9994 - val_loss: 0.1311 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 36/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0095 - acc: 0.9997 - val_loss: 0.1314 - val_acc: 0.9639\n",
      "Epoch 37/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0093 - acc: 0.9996 - val_loss: 0.1313 - val_acc: 0.9641\n",
      "Epoch 38/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0091 - acc: 0.9998 - val_loss: 0.1316 - val_acc: 0.9639\n",
      "Epoch 39/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0090 - acc: 0.9997 - val_loss: 0.1316 - val_acc: 0.9637\n",
      "Epoch 40/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0088 - acc: 0.9998 - val_loss: 0.1321 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 41/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0085 - acc: 0.9998 - val_loss: 0.1321 - val_acc: 0.9641\n",
      "Epoch 42/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0084 - acc: 0.9999 - val_loss: 0.1320 - val_acc: 0.9642\n",
      "Epoch 43/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0083 - acc: 0.9999 - val_loss: 0.1322 - val_acc: 0.9634\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 44/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0081 - acc: 0.9999 - val_loss: 0.1323 - val_acc: 0.9634\n",
      "Epoch 45/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0081 - acc: 0.9999 - val_loss: 0.1323 - val_acc: 0.9637\n",
      "Epoch 46/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0080 - acc: 0.9999 - val_loss: 0.1322 - val_acc: 0.9642\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 47/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0080 - acc: 0.9999 - val_loss: 0.1323 - val_acc: 0.9638\n",
      "Epoch 48/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0079 - acc: 0.9999 - val_loss: 0.1323 - val_acc: 0.9638\n",
      "Epoch 49/100\n",
      "21104/21104 [==============================] - 1s 51us/step - loss: 0.0079 - acc: 0.9999 - val_loss: 0.1324 - val_acc: 0.9638\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 50/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0079 - acc: 0.9999 - val_loss: 0.1324 - val_acc: 0.9638\n",
      "Epoch 51/100\n",
      "21104/21104 [==============================] - 1s 46us/step - loss: 0.0079 - acc: 0.9999 - val_loss: 0.1324 - val_acc: 0.9637\n",
      "Epoch 52/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0078 - acc: 0.9999 - val_loss: 0.1324 - val_acc: 0.9637\n",
      "Epoch 53/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0078 - acc: 0.9999 - val_loss: 0.1324 - val_acc: 0.9637\n",
      "Epoch 54/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0078 - acc: 0.9999 - val_loss: 0.1324 - val_acc: 0.9636\n",
      "Epoch 55/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0078 - acc: 0.9999 - val_loss: 0.1325 - val_acc: 0.9637\n",
      "Epoch 56/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9637\n",
      "Epoch 57/100\n",
      "21104/21104 [==============================] - 1s 46us/step - loss: 0.0078 - acc: 0.9999 - val_loss: 0.1325 - val_acc: 0.9637\n",
      "Epoch 58/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9636\n",
      "Epoch 59/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9637\n",
      "Epoch 60/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9637\n",
      "Epoch 61/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9637\n",
      "Epoch 62/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9637\n",
      "Epoch 63/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9636\n",
      "Epoch 64/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9636\n",
      "Epoch 65/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9637\n",
      "Epoch 66/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9637\n",
      "Epoch 67/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9637\n",
      "Epoch 68/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9635\n",
      "Epoch 69/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9637\n",
      "Epoch 70/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9639\n",
      "Epoch 71/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9639\n",
      "Epoch 72/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9639\n",
      "Epoch 73/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9639\n",
      "Epoch 74/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9641\n",
      "Epoch 75/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9639\n",
      "Epoch 76/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9639\n",
      "Epoch 77/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9640\n",
      "Epoch 78/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9639\n",
      "Epoch 79/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9638\n",
      "Epoch 80/100\n",
      "21104/21104 [==============================] - 1s 51us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9639\n",
      "Epoch 81/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9639\n",
      "Epoch 82/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9638\n",
      "Epoch 83/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9639\n",
      "Epoch 84/100\n",
      "21104/21104 [==============================] - 1s 47us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9640\n",
      "Epoch 85/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9639\n",
      "Epoch 86/100\n",
      "21104/21104 [==============================] - 1s 51us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9641\n",
      "Epoch 87/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9639\n",
      "Epoch 88/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9639\n",
      "Epoch 89/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9639\n",
      "Epoch 90/100\n",
      "21104/21104 [==============================] - 1s 48us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9638\n",
      "Epoch 91/100\n",
      "21104/21104 [==============================] - 1s 52us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9638\n",
      "Epoch 92/100\n",
      "21104/21104 [==============================] - 1s 52us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9640\n",
      "Epoch 93/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9641\n",
      "Epoch 94/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9641\n",
      "Epoch 95/100\n",
      "21104/21104 [==============================] - 1s 51us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9640\n",
      "Epoch 96/100\n",
      "21104/21104 [==============================] - 1s 50us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9641\n",
      "Epoch 97/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9638\n",
      "Epoch 98/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9638\n",
      "Epoch 99/100\n",
      "21104/21104 [==============================] - 1s 52us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9638\n",
      "Epoch 100/100\n",
      "21104/21104 [==============================] - 1s 49us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9640\n"
     ]
    }
   ],
   "source": [
    "# fitted_model = model.fit(X_train, y_train, batch_size=32, epochs=15, verbose=1)\n",
    "fitted_model = model.fit(X_train, y_train, validation_split=0.33,\n",
    "                         callbacks=[learning_rate_reduction], batch_size=50, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 0s 18us/step\n",
      "(10500, 10)\n"
     ]
    }
   ],
   "source": [
    "# Prediction:\n",
    "y_pridict = model.predict(X_test, verbose=1)\n",
    "print (y_pridict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 0s 19us/step\n",
      "The accuracy is:  0.9647619047619047\n"
     ]
    }
   ],
   "source": [
    "# Evaluation:\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('The accuracy is: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000,)\n"
     ]
    }
   ],
   "source": [
    "# Prediction:\n",
    "predicted_classes = model.predict_classes(test)\n",
    "print (predicted_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.DataFrame({\"ImageId\": list(range(1, len(predicted_classes)+1)),\n",
    "                           \"Label\": predicted_classes})\n",
    "submissions.to_csv(\"mnistSubmission.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
